{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Taller de Machine Learning: Predicción de Aprobación de Préstamos 🏦💰\n","\n","En este taller usaremos un dataset de Kaggle para predecir si a una persona se le aprobará o no un préstamo bancario, a partir de información socioeconómica.\n","\n","👉 Dataset: [Bank Loan Data - Kaggle](https://www.kaggle.com/datasets/udaymalviya/bank-loan-data)\n","\n","## Objetivo del Taller\n","1. Preparar el entorno y cargar las librerías necesarias\n","2. Importar y explorar los datos\n","3. Preprocesar los datos\n","4. Entrenar al menos 3 modelos de clasificación\n","5. Evaluar su desempeño\n","6. Elegir el mejor modelo\n","\n","\n","![Bank Loan](https://visbanking.com/wp-content/uploads/2023/02/The-Ultimate-Guide-to-Bank-Loans-.jpeg)\n","\n","<!-- Taller preparado por Andres Muñoz (anguihero) con el fin de formar profesionales en ciencia de datos -->"],"metadata":{"id":"dp8_ekmdfwoz"}},{"cell_type":"markdown","source":["## 📄 Overview del Dataset: Bank Loan Data\n","\n","Este dataset contiene **45,000 registros** de solicitantes de préstamos, con atributos que reflejan información demográfica, situación financiera y detalles del préstamo. Es ideal para tareas de modelado predictivo, especialmente en **evaluación de riesgo crediticio** y **predicción de incumplimiento de préstamos**.\n","\n","---\n","\n","### 📊 Contenido del Dataset\n","\n","El dataset incluye **14 columnas** agrupadas en las siguientes categorías:\n","\n","#### 🧍 Información Personal\n","- `person_age`: Edad del solicitante (en años)\n","- `person_gender`: Género (male, female)\n","- `person_education`: Nivel educativo (High School, Bachelor, Master, etc.)\n","- `person_income`: Ingreso anual (USD)\n","- `person_emp_exp`: Años de experiencia laboral\n","- `person_home_ownership`: Tipo de vivienda (RENT, OWN, MORTGAGE)\n","\n","#### 💰 Detalles del Préstamo\n","- `loan_amnt`: Monto solicitado (USD)\n","- `loan_intent`: Propósito del préstamo (PERSONAL, EDUCATION, MEDICAL, etc.)\n","- `loan_int_rate`: Tasa de interés (%)\n","- `loan_percent_income`: Relación préstamo/ingreso\n","\n","#### 📂 Historial Crediticio\n","- `cb_person_cred_hist_length`: Años de historial crediticio\n","- `credit_score`: Puntaje de crédito\n","- `previous_loan_defaults_on_file`: ¿Registra incumplimientos anteriores? (Yes/No)\n","\n","#### 🎯 Variable Objetivo\n","- `loan_status`: 1 si el préstamo fue pagado exitosamente, 0 si hubo incumplimiento\n","\n","---\n","\n","### 💡 Casos de Uso\n","\n","- **Predicción de incumplimiento**: Clasificar si un préstamo será pagado o no.\n","- **Análisis de riesgo crediticio**: Examinar la relación entre ingreso, puntaje crediticio e incumplimiento.\n","- **Ingeniería de características**: Extraer valor de variables como experiencia laboral, tipo de vivienda y monto del préstamo.\n","\n","---\n","\n","### 📌 Aclaración\n","Este dataset es **sintético** y fue diseñado con fines educativos, de análisis financiero y desarrollo de modelos de *machine learning*.\n","\n"],"metadata":{"id":"7wHVlbDeiGMy"}},{"cell_type":"markdown","source":["## 0. Preparar el Entorno de Trabajo 🛠️\n","\n","Antes de comenzar, debemos asegurarnos de que el entorno de trabajo esté correctamente configurado. Esto incluye:\n","\n","- Importar las librerías necesarias para análisis de datos, visualización y machine learning.\n","- Configurar el entorno para visualizar gráficos de manera adecuada.\n","- Silenciar advertencias para evitar ruido innecesario en la ejecución del notebook.\n","\n","📌 **Hint**: Si alguna librería no está instalada, puedes instalarla con `!pip install nombre-libreria`.\n"],"metadata":{"id":"skDpX8dDgoyp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9QYv8C6Xfvmj"},"outputs":[],"source":["# TODO"]},{"cell_type":"markdown","source":["## 1. Cargar el Dataset\n","\n","📌 Asegúrate de descargar el archivo `bank-loan.csv` desde la página de Kaggle y colocarlo en tu misma carpeta que el notebook.\n","\n","\n","Vamos a leerlo usando pandas:"],"metadata":{"id":"SGMZIN6LgpaW"}},{"cell_type":"code","source":["# TODO"],"metadata":{"id":"NezcZoUegz7N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Explorar los datos\n","\n","Vamos a entender la estructura del dataset:\n","- ¿Cuántos registros y columnas tiene?\n","- ¿Qué tipo de variables hay?\n","- ¿Existen valores nulos?\n","- ¿Cómo es la distribución de la variable objetivo?\n","\n","📌 **Hint**: Usa `.info()`, `.describe()`, `.isnull().sum()`, y gráficos de `seaborn`.\n"],"metadata":{"id":"96Vgt6f4g0IS"}},{"cell_type":"code","source":["# TODO"],"metadata":{"id":"khxXSxXGg1Xr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. Preparar datos para el modelo\n","\n","Vamos a:\n","- Seleccionar algunas variables predictoras\n","- Codificar las variables categóricas\n","- Imputar valores nulos\n","- Dividir el dataset en train y test\n","\n","📌 **HintBusca quedarte con la cantidad y mejor calidad adecuada de variables para los modelos."],"metadata":{"id":"KYXBSvi5g1qz"}},{"cell_type":"code","source":["# TODO"],"metadata":{"id":"SaIrlI8Mg3HS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. Ajustar modelos\n","\n","Vamos a entrenar **tres** modelos diferentes, por ejemplo:\n","1. Regresión Logística\n","2. Random Forest\n","3. Máquina de Vectores de Soporte (SVM)\n","4. KNN\n","5. XGBoost\n","6. LightGBM\n","\n","📌 **Hint**: Usa `.fit()` y `.predict()` para cada modelo.\n","\n"],"metadata":{"id":"srdtvB8tg3S7"}},{"cell_type":"code","source":["# TODO"],"metadata":{"id":"GaxpXMtcha3C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. Evaluar desempeño de los modelos\n","\n","Vamos a usar:\n","- Accuracy\n","- Matriz de confusión\n","- Reporte de clasificación\n","\n","📌 **Hint**: Usa `accuracy_score`, `confusion_matrix`, `classification_report`\n"],"metadata":{"id":"MaY8JpnohbKh"}},{"cell_type":"code","source":["# TODO"],"metadata":{"id":"sz1ewt4Uhk-Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 6. Seleccionar el mejor modelo\n","\n","Basado en los resultados de evaluación, elige el modelo con mejor desempeño.\n","\n","📌 **Hint**: Puedes guiarte por la métrica de *Accuracy*, pero también revisa *Precision* y *Recall* para cada clase."],"metadata":{"id":"C_uQAJD7hlOA"}},{"cell_type":"code","source":["# TODO"],"metadata":{"id":"WffIT-cqhl6x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","---\n","<div style=\"text-align:center; font-size:12px; color:#4a6c8a; font-style:italic; margin-top:20px;\">\n","🙏 Gracias por participar y compartir esta ruta de aprendizaje. ¡Con cada aporte, hacemos que la ciencia de datos avance como comunidad!\n","</div>\n","\n","<div style=\"text-align:right; font-size:10px; color:#a0b4d4; font-style:italic; margin-top:30px;\">\n","🔹 Taller preparado por Andres Muñoz (anguihero) con el propósito de formar profesionales en ciencia de datos.\n","</div>\n","\n","---\n","\n","---"],"metadata":{"id":"yu0WvM8xj73W"}},{"cell_type":"code","source":[],"metadata":{"id":"G_RCy3WCj8SD"},"execution_count":null,"outputs":[]}]}