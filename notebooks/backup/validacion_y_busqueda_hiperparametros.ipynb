{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f36ce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def objective(trial):\n",
    "    alpha = trial.suggest_float(\"alpha\", 0.01, 100.0, log=True)\n",
    "    model = Ridge(alpha=alpha)\n",
    "    score = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    return -score.mean()\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"Mejor alpha:\", study.best_params['alpha'])\n",
    "print(\"Mejor MSE:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf15702",
   "metadata": {},
   "source": [
    "\n",
    "# Validación de Modelos: Train/Test Split, Validación Cruzada y Búsqueda de Hiperparámetros\n",
    "\n",
    "Una parte esencial del desarrollo de modelos de machine learning es evaluar correctamente su rendimiento y generalización.\n",
    "\n",
    "---\n",
    "\n",
    "## ¿Por qué es importante la validación?\n",
    "\n",
    "- Para estimar cómo funcionará el modelo en datos nuevos.\n",
    "- Para evitar el sobreajuste.\n",
    "- Para seleccionar los mejores hiperparámetros.\n",
    "\n",
    "---\n",
    "\n",
    "## Temas cubiertos:\n",
    "1. Separación Train/Test\n",
    "2. Validación Cruzada (K-Fold)\n",
    "3. Búsqueda de Hiperparámetros (Grid Search y Random Search)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555fe71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Cargar dataset de ejemplo\n",
    "data = load_diabetes()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f862bfa",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Train/Test Split\n",
    "\n",
    "La forma más simple de validar un modelo es dividir los datos en un conjunto de **entrenamiento** y otro de **prueba**.\n",
    "\n",
    "- **Entrenamiento**: el modelo aprende.\n",
    "- **Prueba**: evaluamos su capacidad de generalización.\n",
    "\n",
    "```python\n",
    "train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e0e195",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "modelo = Ridge(alpha=1.0)\n",
    "modelo.fit(X_train, y_train)\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "print(\"MSE Test:\", mean_squared_error(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a8277d",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Validación Cruzada (Cross-Validation)\n",
    "\n",
    "En lugar de una sola división, **K-Fold Cross-Validation** divide los datos en `k` bloques y entrena el modelo `k` veces, cada vez usando un bloque diferente como prueba.\n",
    "\n",
    "### Beneficios:\n",
    "- Usa más datos para entrenamiento.\n",
    "- Proporciona estimaciones más robustas del desempeño del modelo.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaebd981",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "modelo_cv = Ridge(alpha=1.0)\n",
    "scores = cross_val_score(modelo_cv, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(\"MSE promedio (5-fold CV):\", -np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e884738",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Búsqueda de Hiperparámetros\n",
    "\n",
    "La selección de hiperparámetros se puede automatizar mediante búsqueda en rejilla (**Grid Search**) o aleatoria (**Random Search**).\n",
    "\n",
    "### Grid Search:\n",
    "Prueba todas las combinaciones posibles de parámetros.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "```\n",
    "\n",
    "### Random Search:\n",
    "Prueba un número fijo de combinaciones aleatorias.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169be75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "grid = GridSearchCV(Ridge(), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(\"Mejor alpha:\", grid.best_params_['alpha'])\n",
    "print(\"Mejor MSE (CV):\", -grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06b94e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "param_dist = {'alpha': uniform(0.01, 100)}\n",
    "random_search = RandomizedSearchCV(Ridge(), param_distributions=param_dist, n_iter=10,\n",
    "                                   cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "random_search.fit(X, y)\n",
    "\n",
    "print(\"Alpha óptimo (Random Search):\", random_search.best_params_['alpha'])\n",
    "print(\"MSE óptimo (CV):\", -random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439a380b",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Búsqueda Bayesiana de Hiperparámetros\n",
    "\n",
    "La **búsqueda bayesiana** mejora el proceso de ajuste de hiperparámetros al modelar la función de puntuación como una función probabilística. En lugar de probar combinaciones al azar o exhaustivamente (como en Grid o Random Search), **aprende qué regiones del espacio de búsqueda tienen más probabilidades de contener buenos hiperparámetros** y explora en consecuencia.\n",
    "\n",
    "Se basa en:\n",
    "- Un modelo probabilístico (como Gaussian Process o Tree Parzen Estimator).\n",
    "- Una estrategia de adquisición para decidir qué puntos explorar (como UCB, EI o PI).\n",
    "\n",
    "### Ventajas:\n",
    "- Más eficiente en problemas costosos.\n",
    "- Encuentra buenos parámetros con menos evaluaciones.\n",
    "- Escalable y extensible.\n",
    "\n",
    "### Librerías útiles:\n",
    "- `optuna`\n",
    "- `scikit-optimize (skopt)`\n",
    "- `bayesian-optimization`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cdd748",
   "metadata": {},
   "source": [
    "\n",
    "## Ejercicio Final\n",
    "\n",
    "1. Usa un modelo `Lasso` o `RandomForestRegressor`.\n",
    "2. Aplica GridSearchCV para encontrar los mejores hiperparámetros.\n",
    "3. Usa validación cruzada para comparar diferentes modelos y decidir el mejor.\n",
    "\n",
    "¡Recuerda comparar MSE promedio y ajustar los parámetros correctamente!\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
